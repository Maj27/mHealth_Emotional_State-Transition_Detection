{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hyperparameter tuning of the five classifiers for emotional state detection\n",
    "* 5 fold cross validation with grid-search\n",
    "* Multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import metrics   \n",
    "from sklearn.feature_selection import SelectFromModel,RFECV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score, PredefinedSplit\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "\n",
    "from sklearn import metrics   \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "import re\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "#warnings.filterwarnings('always')\n",
    "import pickle\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from imblearn.metrics import specificity_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import make_scorer, f1_score, roc_auc_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn import metrics   \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "#from pandas_ml import ConfusionMatrix\n",
    "\n",
    "#import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input(p):\n",
    "    #Read input file of each person\n",
    "    filename='data/NOv_w5_emotionLabel_SelFeat_p'+str(p)+'.csv'\n",
    "    raw_df= pd.read_csv(filename)\n",
    "    \n",
    "    #drop all variables that contain all NANs\n",
    "    raw_df.dropna(axis=1,how='all', inplace=True)\n",
    "    #reset the index\n",
    "    raw_df.reset_index(drop=True, inplace=True)\n",
    "    #drop columns with all zeros in pandas dataframe\n",
    "    raw_df=raw_df.T[(raw_df!=0).any()].T\n",
    "    \n",
    "    #print(\"The shape of the dataframe is \",raw_df.shape)\n",
    "    #print(raw_df['emotion'].value_counts())\n",
    "    return raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NANs with -999\n",
    "def prep_data(data):\n",
    "    return data.fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns\n",
    "def drop_cols(data, col_list):\n",
    "    return data.drop(col_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data with minmax\n",
    "def scale_data(trn_x, tst_x):\n",
    "    \n",
    "    sc= StandardScaler()\n",
    "    scaled_trn_x = sc.fit_transform(trn_x)\n",
    "    scaled_tst_x = sc.fit_transform(tst_x)\n",
    "    \n",
    "    return scaled_trn_x, scaled_tst_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampling with SMOTE with 'minority' and 'not majority'\n",
    "def over_sample_SMOTE(X_train, y_train):\n",
    "    sm=SMOTE(sampling_strategy='not majority', random_state=10) # 'minority'\n",
    "    X_train_ovr, y_train_ovr=sm.fit_sample(X_train, y_train)\n",
    "\n",
    "    #print(X_train_ovr.shape, y_train_ovr.shape)\n",
    "    return X_train_ovr, y_train_ovr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampling with SVMSMOTE \n",
    "def over_sample_SVMSMOTE(X_train, y_train):\n",
    "    sm=SVMSMOTE(random_state=10)\n",
    "    \n",
    "    X_train_ovr, y_train_ovr=sm.fit_sample(X_train, y_train)\n",
    "\n",
    "    #print(X_train_ovr.shape, y_train_ovr.shape)\n",
    "    return X_train_ovr, y_train_ovr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_k_features(X_train_scaled,X_test_scaled,y_train,k):\n",
    "    selection = SelectKBest(mutual_info_classif, k)\n",
    "    X_train = selection.fit_transform(X_train_scaled,y_train)\n",
    "    X_test = selection.transform(X_test_scaled)\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define random state to re-generate the same result\n",
    "random_state = 43\n",
    "\n",
    "# total persons\n",
    "p_list=[8, 10,12,13,15,20,21,25, 27, 33,35,40,46,48,49,52,54,55]\n",
    "#p_list=[8]\n",
    "\n",
    "# #of folds\n",
    "n_fold=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(accu, bl_accu, prec, rec_, spec_, roc_, f1_):   \n",
    "    print('.....................')\n",
    "    print(\"Average Accuracy: %.2f%% (%.2f)\" % (np.mean(accu), np.std(accu)))\n",
    "    print(\"Average Balanced_accuracy: %.2f%% (%.2f)\" % (np.mean(bl_accu),np.std(bl_accu)))\n",
    "    print(\"Average Precision: %.2f%% (%.2f)\" % (np.mean(prec),np.std(prec)))\n",
    "    print(\"Average Recall: %.2f%% (%.2f)\" % (np.mean(rec_),np.std(rec_)))\n",
    "    print(\"Average Specificity: %.2f%% (%.2f)\" % (np.mean(spec_),np.std(spec_)))\n",
    "    print(\"Average ROC AUC: %.2f%% (%.2f)\" % (np.mean(roc_),np.std(roc_)))\n",
    "    print(\"Average F1 score: %.2f%% (%.2f)\" % (np.mean(f1_),np.std(f1_)))\n",
    "    print('..................................................')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p_list=[8, 10,12,13,15,20,21,25, 27, 33,35,40,46,48,49,52,54,55]\n",
    "p = 12 \n",
    "\n",
    "# for each person in the dataset, find the best hyperparamters for the model in given range \n",
    "#for p in p_list:\n",
    "df=read_input(p)\n",
    "#df.head()\n",
    "df=prep_data(df)\n",
    "# remove day_of_month variable if present in data\n",
    "if 'day_of_month' in df.columns:\n",
    "    drop_col=['day_of_month']\n",
    "    df=drop_cols(df, drop_col)\n",
    "\n",
    " #remove classes that have less then 5 samples\n",
    "min_c=df['emotion'].value_counts()\n",
    "if (min_c <= 5).any():\n",
    "    r_label=min_c[min_c <= 5].index[0]\n",
    "    df = df.drop(df.index[df.emotion == r_label])\n",
    "\n",
    "  # find the best model and test\n",
    "    #print(\"Person \"+str(p))\n",
    "    #print(\"-------------------------------------------------------\")\n",
    "     #print report\n",
    "    #stats(y_test, pred)\n",
    "   \n",
    "    #print(\"-------------------------------------------------------\")\n",
    "    \n",
    "dataset = df   \n",
    "\n",
    "y = dataset['emotion'].copy()\n",
    "X = dataset.loc[:, dataset.columns != 'emotion'].copy()\n",
    "#X = X.apply(pd.to_numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('scaler', StandardScaler()), # MinMaxScaler()\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k=90)), #\n",
    "                 ('classifier', LogisticRegression())])\n",
    "\n",
    "search_space = [{'selector__k': [ 50, 70, 90]},\n",
    "                \n",
    "                {'classifier': [LogisticRegression(solver='lbfgs')],\n",
    "                 'classifier__C': [0.01, 0.1, 1.0],\n",
    "                 'classifier__penalty': ['l1', 'l2', None],\n",
    "                 'classifier__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                 'classifier__max_iter':[100, 150, 200], \n",
    "                 'classifier__class_weight':[None, 'balanced']},\n",
    "                 \n",
    "                {'classifier': [RandomForestClassifier()],\n",
    "                 'classifier__max_depth': [5, 10, 30, None],\n",
    "                 'classifier__criterion':['gini','entropy'], \n",
    "                 'classifier__bootstrap': [True],\n",
    "                 'classifier__max_features':['log2', None],\n",
    "                 'classifier__n_estimators': [50, 100, 200, 300, 400]},\n",
    "                \n",
    "                {'classifier': [MLPClassifier(random_state=1, early_stopping=True)],\n",
    "                 'classifier__hidden_layer_sizes' : [(50, 50, 50), (50, 100, 50), (20, 20, 20), (30, ), (50,),(100,)], \n",
    "                 'classifier__activation' : ['tanh', 'relu', 'logistic'],\n",
    "                 'classifier__max_iter':[50, 100, 150, 200, 300],\n",
    "                 'classifier__solver': ['sgd', 'adam', 'lbfgs'],\n",
    "                 'classifier__alpha': [0.0001, 0.001, 0.05]},\n",
    "                \n",
    "                {'classifier': [CatBoostClassifier(random_seed=1)],\n",
    "                 'classifier__learning_rate': [0.05, 0.1, 0.15, 0.2]},\n",
    "                \n",
    "                {'classifier': [xgb.XGBClassifier(random_state=1)],\n",
    "                 'classifier__learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
    "                 'classifier__colsample_bytree':[.5, .75, 1],\n",
    "                 'classifier__max_depth': np.arange(3, 6, 10),\n",
    "                 'classifier__n_estimators': [50, 100, 200, 300, 400]}]\n",
    "                  \n",
    "     \n",
    "scorers = {\n",
    "    'precision_score': make_scorer(precision_score, average='macro'),\n",
    "    'recall_score': make_scorer(recall_score, average='macro'),\n",
    "    'accuracy_score': make_scorer(accuracy_score, average='macro')\n",
    "}\n",
    "\n",
    "scorer = make_scorer(f1_score, average = 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_pipe = Pipeline([('scaler', StandardScaler()), # MinMaxScaler()\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k=90)), #\n",
    "                 ('classifier', LogisticRegression())])\n",
    "\n",
    "LR_search_space = [{'selector__k': [ 50, 70, 90, 110]},\n",
    "                \n",
    "                {'classifier': [LogisticRegression(solver='lbfgs')],\n",
    "                 'classifier__C': [0.01, 0.1, 1.0],\n",
    "                 'classifier__penalty': ['l1', 'l2', None],\n",
    "                 'classifier__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                 'classifier__max_iter':[100, 150, 200], \n",
    "                 'classifier__class_weight':[None, 'balanced']}]\n",
    "                 \n",
    "################################################################################          \n",
    "\n",
    "RF_pipe = Pipeline([('scaler', StandardScaler()), # MinMaxScaler()\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k=90)), #\n",
    "                 ('classifier', RandomForestClassifier())])\n",
    "\n",
    "RF_search_space = [{'selector__k': [ 50, 70, 90, 110]},\n",
    "                \n",
    "                {'classifier': [RandomForestClassifier()],\n",
    "                 'classifier__max_depth': [5, 10, 30, None],\n",
    "                 'classifier__criterion':['gini','entropy'], \n",
    "                 'classifier__bootstrap': [True],\n",
    "                 'classifier__max_features':['log2', None],\n",
    "                 'classifier__n_estimators': [50, 100, 200, 300, 400]}]\n",
    "                  \n",
    "################################################################################\n",
    "\n",
    "MLP_pipe = Pipeline([('scaler', StandardScaler()), # MinMaxScaler()\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k=90)), #\n",
    "                 ('classifier', MLPClassifier(random_state=1, early_stopping=True))])\n",
    "\n",
    "MLP_search_space = [{'selector__k': [ 50, 70, 90, 110]},\n",
    "                \n",
    "                {'classifier': [MLPClassifier(random_state=1, early_stopping=True)],\n",
    "                 'classifier__hidden_layer_sizes' : [(50, 50, 50), (50, 100, 50), (20, 20, 20), (30, ), (50,),(100,)], \n",
    "                 'classifier__activation' : ['tanh', 'relu', 'logistic'],\n",
    "                 'classifier__max_iter':[50, 100, 150, 200, 300],\n",
    "                 'classifier__solver': ['sgd', 'adam', 'lbfgs'],\n",
    "                 'classifier__alpha': [0.0001, 0.001, 0.05]}]\n",
    "\n",
    "################################################################################\n",
    "\n",
    "CB_pipe = Pipeline([('scaler', StandardScaler()), # MinMaxScaler()\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k=90)), #\n",
    "                 ('classifier', CatBoostClassifier(random_seed=1))])\n",
    "\n",
    "CB_search_space = [{'selector__k': [ 50, 70, 90, 110]},\n",
    "                \n",
    "                {'classifier': [CatBoostClassifier(random_seed=1, verbose=False)],\n",
    "                 'classifier__learning_rate': [0.05, 0.1, 0.15, 0.2]}]\n",
    "\n",
    "################################################################################\n",
    "\n",
    "XGB_pipe = Pipeline([('scaler', StandardScaler()), # MinMaxScaler()\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k=90)), #\n",
    "                 ('classifier', xgb.XGBClassifier(random_state=1))])\n",
    "\n",
    "XGB_search_space = [{'selector__k': [ 50, 70, 90, 110]},\n",
    "                \n",
    "                {'classifier': [xgb.XGBClassifier(random_state=1)],\n",
    "                 'classifier__learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
    "                 'classifier__colsample_bytree':[.5, .75, 1],\n",
    "                 'classifier__max_depth': np.arange(3, 6, 10),\n",
    "                 'classifier__n_estimators': [50, 100, 200, 300, 400]}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_wrapper(pipe = pipe, search_space = search_space, verbose= False,refit_score=scorer):\n",
    "    \"\"\"\n",
    "    fits a GridSearchCV classifiers using refit_score for optimization\n",
    "    prints classifier performance metrics\n",
    "    \"\"\"\n",
    "    cross_validation = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "\n",
    "    grid_search = GridSearchCV(pipe, search_space, cv=cross_validation, verbose=verbose,  n_jobs = -1) #scoring=scorer, refit=scorer\n",
    "    \n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    return grid_search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 274 candidates, totalling 1370 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   46.6s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1370 out of 1370 | elapsed:  6.6min finished\n",
      "/Users/majed_al-jefri/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "pipeline_grid_search_LR = grid_search_wrapper(pipe = LR_pipe, search_space = LR_search_space, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('selector',\n",
      "                 SelectKBest(k=90,\n",
      "                             score_func=<function mutual_info_classif at 0x1a1ff22710>)),\n",
      "                ('classifier',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='auto', n_jobs=None,\n",
      "                                    penalty='l2', random_state=None,\n",
      "                                    solver='newton-cg', tol=0.0001, verbose=0,\n",
      "                                    warm_start=False))],\n",
      "         verbose=False)\n",
      "0.9166666666666667\n"
     ]
    }
   ],
   "source": [
    "print(pipeline_grid_search_LR.best_estimator_)\n",
    "print(pipeline_grid_search_LR.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 84 candidates, totalling 420 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 420 out of 420 | elapsed:  3.5min finished\n"
     ]
    }
   ],
   "source": [
    "pipeline_grid_search_RF = grid_search_wrapper(pipe = RF_pipe, search_space = RF_search_space, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='entropy', max_depth=None, max_features=None,\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=400,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "0.9685185185185186\n"
     ]
    }
   ],
   "source": [
    "print(pipeline_grid_search_RF.best_estimator_['classifier'])\n",
    "print(pipeline_grid_search_RF.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 814 candidates, totalling 4070 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   45.8s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1969 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3265 tasks      | elapsed: 16.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed: 20.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4070 out of 4070 | elapsed: 20.6min finished\n"
     ]
    }
   ],
   "source": [
    "pipeline_grid_search_MLP = grid_search_wrapper(pipe = MLP_pipe, search_space = MLP_search_space, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
      "              beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(50,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=1, shuffle=True, solver='lbfgs',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False), 'classifier__activation': 'logistic', 'classifier__alpha': 0.0001, 'classifier__hidden_layer_sizes': (50,), 'classifier__max_iter': 200, 'classifier__solver': 'lbfgs'}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'GridSearchCV' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-cc0aa69739a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_grid_search_MLP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpipeline_grid_search_MLP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_index_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_grid_search_MLP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classifier'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'GridSearchCV' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(pipeline_grid_search_MLP.cv_results_['params'][pipeline_grid_search_MLP.best_index_])\n",
    "print(pipeline_grid_search_MLP['classifier'].best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 320 out of 320 | elapsed:  3.3min finished\n"
     ]
    }
   ],
   "source": [
    "pipeline_grid_search_XGB = grid_search_wrapper(pipe = XGB_pipe, search_space = XGB_search_space, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('selector',\n",
      "                 SelectKBest(k=90,\n",
      "                             score_func=<function mutual_info_classif at 0x1a1ff22710>)),\n",
      "                ('classifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=0.5, gamma=0,\n",
      "                               learning_rate=0.05, max_delta_step=0,\n",
      "                               max_depth=3, min_child_weight=1, missing=None,\n",
      "                               n_estimators=400, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=1,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "0.962962962962963\n"
     ]
    }
   ],
   "source": [
    "print(pipeline_grid_search_XGB.best_estimator_)\n",
    "print(pipeline_grid_search_XGB.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_grid_search_CB = grid_search_wrapper(pipe = CB_pipe, search_space = CB_search_space, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "0.9703703703703702\n"
     ]
    }
   ],
   "source": [
    "print(str(pipeline_grid_search_CB.best_estimator_['selector'])[14:16])\n",
    "print(pipeline_grid_search_CB.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pps = [pipeline_grid_search_CB, pipeline_grid_search_RF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x11f7decd0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pps[0].best_estimator_['classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = {} # dictionary of best models with best parameters\n",
    "\n",
    "best_models['Logistic Regression'] = LR_model\n",
    "best_models['RandomForest Classifier'] = RF_model\n",
    "best_models['MLP Classifier'] = MLP_model\n",
    "best_models['XGBoost Classifier'] = XGB_model\n",
    "best_models['CatBoost Classifier'] = CB_model\n",
    "\n",
    "n_features = [90, 90, 90, 90, 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restuls for:  Logistic Regression\n",
      ".....................\n",
      "Average Accuracy: 64.43% (9.97)\n",
      "Average Balanced_accuracy: 63.78% (9.97)\n",
      "Average Precision: 57.88% (10.68)\n",
      "Average Recall: 66.03% (10.27)\n",
      "Average Specificity: 86.16% (7.56)\n",
      "Average ROC AUC: 84.52% (7.09)\n",
      "Average F1 score: 56.73% (10.58)\n",
      "..................................................\n",
      "\n",
      "\n",
      "Restuls for:  RandomForest Classifier\n",
      ".....................\n",
      "Average Accuracy: 80.67% (9.27)\n",
      "Average Balanced_accuracy: 67.23% (16.30)\n",
      "Average Precision: 82.42% (6.91)\n",
      "Average Recall: 72.07% (10.89)\n",
      "Average Specificity: 88.93% (7.63)\n",
      "Average ROC AUC: 94.43% (3.23)\n",
      "Average F1 score: 72.33% (10.90)\n",
      "..................................................\n",
      "\n",
      "\n",
      "Restuls for:  MLP Classifier\n",
      ".....................\n",
      "Average Accuracy: 22.90% (16.90)\n",
      "Average Balanced_accuracy: 27.46% (5.24)\n",
      "Average Precision: 23.76% (16.89)\n",
      "Average Recall: 85.18% (14.03)\n",
      "Average Specificity: 18.83% (19.29)\n",
      "Average ROC AUC: 52.45% (4.91)\n",
      "Average F1 score: 28.28% (15.49)\n",
      "..................................................\n",
      "\n",
      "\n",
      "Restuls for:  XGBoost Classifier\n",
      ".....................\n",
      "Average Accuracy: 82.78% (8.41)\n",
      "Average Balanced_accuracy: 73.28% (13.45)\n",
      "Average Precision: 80.60% (9.13)\n",
      "Average Recall: 75.93% (11.77)\n",
      "Average Specificity: 91.99% (4.68)\n",
      "Average ROC AUC: 95.48% (2.81)\n",
      "Average F1 score: 74.49% (12.20)\n",
      "..................................................\n",
      "\n",
      "\n",
      "Restuls for:  CatBoost Classifier\n",
      ".....................\n",
      "Average Accuracy: 86.40% (9.27)\n",
      "Average Balanced_accuracy: 76.92% (16.50)\n",
      "Average Precision: 86.92% (5.98)\n",
      "Average Recall: 79.54% (13.02)\n",
      "Average Specificity: 92.62% (6.61)\n",
      "Average ROC AUC: 97.07% (2.16)\n",
      "Average F1 score: 79.71% (12.94)\n",
      "..................................................\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this is to get all the detailed performance meterics after selecting the best model parameters\n",
    "\n",
    "skf=StratifiedKFold(n_splits=nfolds, shuffle=True, random_state=random_state)\n",
    "k_i = -1\n",
    "\n",
    "for model_name, model in best_models.items(): \n",
    "    k_i = k_i + 1\n",
    "    accu = []\n",
    "    prec = []\n",
    "    rec_ = []\n",
    "    f1_ = []\n",
    "    bl_accu = []\n",
    "    roc_ = []\n",
    "    spec_ = []\n",
    "\n",
    "    for p in p_list:\n",
    "        \n",
    "        df=read_input(p)\n",
    "        #df.head()\n",
    "        df=prep_data(df)\n",
    "        # remove day_of_month variable if present in data\n",
    "        if 'day_of_month' in df.columns:\n",
    "            drop_col=['day_of_month']\n",
    "            df=drop_cols(df, drop_col)\n",
    "\n",
    "         #remove classes that have less then 5 samples\n",
    "        min_c=df['emotion'].value_counts()\n",
    "        if (min_c <= 5).any():\n",
    "            r_label=min_c[min_c <= 5].index[0]\n",
    "            df = df.drop(df.index[df.emotion == r_label])\n",
    "\n",
    "        dataset = df   \n",
    "\n",
    "        y = dataset['emotion'].copy()\n",
    "        X = dataset.loc[:, dataset.columns != 'emotion'].copy()\n",
    "\n",
    "        \n",
    "        avg_ac=0.0\n",
    "        avg_bl_ac=0.0\n",
    "        avg_rc=0.0\n",
    "        avg_pr=0.0\n",
    "        avg_f1=0.0\n",
    "        avg_spec=0.0\n",
    "        avg_roc=0.0\n",
    "        avg_kp=0.0\n",
    "\n",
    "        i = 1\n",
    "        for train_index, test_index in skf.split(X ,y):\n",
    "            #print(\"fold\", i)\n",
    "            i+=1\n",
    "\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index] \n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            #scale features\n",
    "            X_train_scaled, X_test_scaled= scale_data(X_train, X_test) \n",
    "            #feature selection\n",
    "            X_train, X_test = select_k_features(X_train_scaled,X_test_scaled,y_train,k=n_features[k_i])\n",
    "\n",
    "            #oversample training data\n",
    "            #X_train_imb,y_train_imb=over_sample_SMOTE(X_train, y_train)\n",
    "            #X_train_imb,y_train_imb=over_sample_SMOTENC(X_train, y_train, index1, index2)\n",
    "            X_train_imb,y_train_imb=over_sample_SVMSMOTE(X_train, y_train)\n",
    "\n",
    "\n",
    "            # train model on imbalance-handled data\n",
    "            model.fit(X_train_imb, y_train_imb)\n",
    "\n",
    "            #train model on imbalance data \n",
    "            #model.fit(X_train, y_train)\n",
    "\n",
    "            # test model, measure class label and probability score\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_scores = model.predict_proba(X_test)\n",
    "\n",
    "            #calculate metrices\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            bl_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "            precision=precision_score(y_test, y_pred,  average='macro',labels=np.unique(y_pred)) #'weighted', 'micro', 'micro'\n",
    "            recall=recall_score(y_test, y_pred,  average='macro',labels=np.unique(y_pred))\n",
    "            #kappa=cohen_kappa_score(y_pred, y_test)\n",
    "            spec=specificity_score(y_test, y_pred, average='macro',labels=np.unique(y_pred))\n",
    "            #roc=roc_auc_score(y_test, y_scores, multi_class='ovr', average='macro')\n",
    "            f1=f1_score(y_test, y_pred,  average='macro',labels=np.unique(y_pred))\n",
    "\n",
    "            # sometimes not all classes are present in the test set\n",
    "            not_present = list(set(model.classes_)-set(y_test.unique()))\n",
    "            # get that class\n",
    "            if not_present:\n",
    "                not_present=not_present[0] # get the element then its index\n",
    "                ind= list(model.classes_).index(not_present)\n",
    "                y_scores = np.delete(y_scores,ind,1) # delete it from the scores\n",
    "                y_scores = y_scores / y_scores.sum(axis=1)[:,None]  #make sure sum equals ro 0 (sum of probabilities)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "            roc=roc_auc_score(y_test, y_scores, multi_class='ovr', average='macro')\n",
    "\n",
    "            ac=accuracy * 100.0\n",
    "            pr=precision*100\n",
    "            rc=recall*100\n",
    "            f1_p=f1*100\n",
    "            bl_ac=bl_accuracy*100\n",
    "            roc=roc*100\n",
    "            spec=spec*100\n",
    "\n",
    "\n",
    "            #update average metrices in each fold\n",
    "            avg_ac+=ac\n",
    "            avg_bl_ac+=bl_ac\n",
    "            avg_rc+=rc\n",
    "            avg_pr+=pr\n",
    "            avg_f1+=f1_p\n",
    "            avg_roc+=roc\n",
    "            avg_spec+=spec\n",
    "    \n",
    "        avg_ac = avg_ac/nfolds\n",
    "        avg_bl_ac = avg_bl_ac/nfolds\n",
    "        avg_rc = avg_rc/nfolds\n",
    "        avg_pr = avg_pr/nfolds\n",
    "        avg_f1 = avg_f1/nfolds\n",
    "        avg_roc = avg_roc/nfolds\n",
    "        avg_spec = avg_spec/nfolds\n",
    "            \n",
    "        accu.append(avg_ac)\n",
    "        prec.append(avg_pr)\n",
    "        rec_.append(avg_rc)\n",
    "        f1_.append(avg_f1)\n",
    "        bl_accu.append(avg_bl_ac)\n",
    "        roc_.append(avg_roc)\n",
    "        spec_.append(avg_spec)\n",
    "    \n",
    "    print('Restuls for: ', model_name)\n",
    "    print_results(accu, bl_accu, prec, rec_, spec_, roc_, f1_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
